<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>N√ºrnberg | GeoBrinkmann</title>
    <link>https://geobrinkmann.com/tags/nurnberg/</link>
      <atom:link href="https://geobrinkmann.com/tags/nurnberg/index.xml" rel="self" type="application/rss+xml" />
    <description>N√ºrnberg</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 14 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://geobrinkmann.com/media/icon_hu11167265919780470973.png</url>
      <title>N√ºrnberg</title>
      <link>https://geobrinkmann.com/tags/nurnberg/</link>
    </image>
    
    <item>
      <title>N√ºrnberg - 2. Greenspace Availability Index (GAVI)</title>
      <link>https://geobrinkmann.com/post/nuernberg-greenspace-availability-index/</link>
      <pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://geobrinkmann.com/post/nuernberg-greenspace-availability-index/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Greenspace availability plays a critical role in understanding the impact of urban environments on human health and well-being. One common approach to measuring greenspace availability is through simple 2D buffer analyses around residential or workplace locations using remote sensing data, such as the Normalized Difference Vegetation Index (NDVI) or land-use/land-cover (LULC) maps (Labib, Lindley, and Huck 2020a). These indices help quantify photosynthetically active vegetation and the proportion of green land cover. Moreover, to address seasonal variations and different qualities of greenspace, researchers recommend using multiple remote sensing products at various scales (Markevych et al. 2017; Labib, Lindley, and Huck 2020b). Beyond its general relevance for urban public health, greenspace availability is especially vital for mitigating environmental stressors - an important aspect of reducing harm in cities (Markevych et al. 2017).&lt;/p&gt;
&lt;p&gt;Urban areas are often associated with elevated levels of air pollution, heat, and noise - factors that can negatively impact mental and physical health (Dadvand and Nieuwenhuijsen 2019). Studies indicate that higher concentrations of greenspace help reduce traffic-related air pollution through plant uptake and deposition on leaf surfaces (Givoni 1991; Paoletti et al. 2011; Nowak et al. 2014). Consequently, air pollutant concentrations are generally lower in greener areas, and exposure to greenspace near schools and residential districts can mitigate adverse effects such as depression and cognitive deficits in children (Su et al. 2011; Dadvand et al. 2012, 2015; Ali and Khoja 2019). Furthermore, the urban heat island effect, mainly caused by the replacement of vegetation with built-up infrastructure like concrete and high-rise buildings, exacerbates local temperatures and reduces wind flow (Voogt and Oke 2003; Phelan et al. 2015; Heaviside, Macintyre, and Vardoulakis 2017). Exposure to high temperatures is linked to increased hospital admissions and mortality (Basu 2009; D‚ÄôIppoliti et al. 2010), and there is emerging evidence of elevated mental health risks during extreme heat events (Nori-Sarma et al. 2022). Together, these findings underscore the importance of incorporating greenspace into urban planning to mitigate environmental stressors and safeguard public health - key considerations for the development of indices such as the GAVI (Greenspace Availability Index).&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;The relevant spatial datasets have been uploaded on Zenodo: administrative boundaries (AOI), NDVI and LAI rasters, and a binary land-cover raster for greenspace analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dplyr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;terra&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CGEI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;https://zenodo.org/records/14633167/files/&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# AOI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;read_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;01_Nbg_Bezirke.gpkg&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code_bez&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;97&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# This is not available in the GAVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;group_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code_bez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name_bez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;summarise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ungroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# NDVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;ndvi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_ndvi_10m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# LAI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lai&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_lai_10m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Greenspace (binary)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lulc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_lulc_10m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;https://geobrinkmann.com/post/nuernberg-greenspace-availability-index/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;
&lt;p&gt;N√ºrnberg, shown on the left in grey, is divided into 86 administrative districts. M√∂geldorf has been highlighted in orange to provide examples of the three key greenness metrics on the right:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NDVI&lt;/strong&gt; highlights areas of more intense photosynthetic activity in greener hues&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LAI&lt;/strong&gt; shows the density of foliage based on leaf area&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LULC&lt;/strong&gt; distinguishes vegetated areas (green) from non-vegetated surfaces (red)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;lacunarity&#34;&gt;Lacunarity&lt;/h2&gt;
&lt;p&gt;Lacunarity is a key measure of spatial heterogeneity - often described as the ‚Äúgappiness‚Äù of a pattern - making it especially useful for characterizing how vegetation is distributed across landscapes (Labib, Lindley, and Huck 2020b; Hoechstetter, Walz, and Thinh 2011). While other measures simply aggregate the amount of greenspace, lacunarity captures differences in the &lt;strong&gt;structure&lt;/strong&gt; of that greenspace. For instance, a continuous patch of trees will exhibit lower lacunarity than an area of fragmented green spots, even if both have the same total leaf cover.&lt;/p&gt;
&lt;p&gt;This insight is critically important in urban contexts, where the spatial arrangement of vegetation affects microclimate regulation, air pollution buffering, and recreational opportunities. Moreover, lacunarity helps address the &lt;strong&gt;modifiable areal unit problem (MAUP)&lt;/strong&gt; by examining multiple scales simultaneously. Smaller scales might capture local vegetation buffers (e.g., shrubs along roadways), while larger scales reflect broader landscape connectivity and potential for recreational use.&lt;/p&gt;
&lt;p&gt;In practice, lacunarity is calculated by sliding a square window of varying buffer sizes across a raster (e.g., NDVI, LAI, or LULC), then quantifying how homogeneous or heterogeneous each neighborhood is at each scale. The result is a scale-dependent measure of pattern variation. Below is an example of how lacunarity can be computed at five buffer distances (50, 100, 200, 300, and 400 meters) using the &lt;a href=&#34;https://github.com/STBrinkmann/CGEI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;CGEI&lt;/strong&gt;&lt;/a&gt; R package:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Combine rasters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;rast_vec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ndvi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lai&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lulc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Calculate Lacunarity at 5 relevant levels: 50m, 100m, 200m, 300m, 400m&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lac_nbg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;lacunarity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rast_vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                      &lt;span class=&#34;n&#34;&gt;r_vec&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;50&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;400&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                      &lt;span class=&#34;n&#34;&gt;cores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;22L&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Below is a log‚Äìlog plot of lacunarity &lt;code&gt;\(ùõ¨(r)\)&lt;/code&gt; against the neighborhood size &lt;code&gt;\(r\)&lt;/code&gt;. Conceptually, as we increase the size of the moving window (similar to a focal analysis), we average over a larger area, making the image appear more homogeneous - in other words, small-scale patchiness becomes less visible at bigger scales.&lt;/p&gt;
&lt;img src=&#34;Lacunarity_summary.svg&#34; width=&#34;439&#34; /&gt;
&lt;p&gt;From the plot, we see that NDVI and LAI start with relatively high lacunarity and then quickly decline, suggesting that vegetation density becomes more uniform as we ‚Äúzoom out.‚Äù Meanwhile, LULC begins at a higher lacunarity level and still remains above 0.25 at larger distances, meaning binary greenspace (presence or absence) is initially more ‚Äúpatchy‚Äù at small scales and smooths out at very larg scales. Overall, all three measures - NDVI, LAI, and LULC - show a reduction in spatial heterogeneity with increasing window size, consistent with the smoothing effect of larger-scale aggregation.&lt;/p&gt;
&lt;p&gt;When we combine multiple metrics (e.g., NDVI, LAI, LULC) across multiple scales (e.g., 50 m to 400 m) using lacunarity-based weights, we capture:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Different ecosystem functions at different neighborhood sizes - smaller buffers highlight local vegetation that filters pollution and noise, while larger buffers capture larger green spaces like parks.&lt;/li&gt;
&lt;li&gt;Spatial structure - fragmented or ‚Äúgappy‚Äù greenspace has higher lacunarity at small scales, but becomes more uniform at larger scales.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;By assigning individual weights for each metric and scale (based on how patchy they are), we ensure that not all neighborhood sizes contribute equally to people‚Äôs overall exposure. This strategy also helps mitigate the Modifiable Areal Unit Problem (MAUP), producing a Greenspace Availability Index (GAVI) that reflects both the quantity of greenspace and its arrangement at scales meaningful for human well-being.&lt;/p&gt;
&lt;h2 id=&#34;gavi&#34;&gt;GAVI&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Calculate GAVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;gavi_nbg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;gavi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rast_vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lac_nbg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;gavi_nbg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;GAVI&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Below is the &lt;strong&gt;final Greenspace Availability Index (GAVI) map&lt;/strong&gt; for N√ºrnberg, derived by combining NDVI, LAI, and LULC across five spatial scales (50 m to 400 m) using &lt;strong&gt;lacunarity-based weights&lt;/strong&gt;. The map highlights where greenspace is low (red shades, corresponding to lower GAVI values) and high (green shades, corresponding to higher GAVI values). Unsurprisingly, dense urban areas toward the city center show lower greenspace availability, while more peripheral or park-rich districts exhibit higher levels of greenery.&lt;/p&gt;
&lt;p&gt;By capturing both the amount and the spatial arrangement of vegetation at multiple neighborhood scales, this multi-scale, multi-metric approach provides a &lt;strong&gt;more nuanced picture&lt;/strong&gt; of greenspace availability - valuable for urban planning, public health, and environmental management.&lt;/p&gt;
&lt;img src=&#34;https://geobrinkmann.com/post/nuernberg-greenspace-availability-index/index.en_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;768&#34; /&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; entry-spacing=&#34;0&#34;&gt;
&lt;div id=&#34;ref-ali2019&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Ali, Naureen A., and Adeel Khoja. 2019. ‚ÄúGrowing Evidence for the Impact of Air Pollution on Depression.‚Äù &lt;em&gt;Ochsner Journal&lt;/em&gt; 19 (1): 4‚Äì4. &lt;a href=&#34;https://doi.org/10.31486/toj.19.0011&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.31486/toj.19.0011&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-basu2009&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Basu, Rupa. 2009. ‚ÄúHigh Ambient Temperature and Mortality: A Review of Epidemiologic Studies from 2001 to 2008.‚Äù &lt;em&gt;Environmental Health&lt;/em&gt; 8 (1). &lt;a href=&#34;https://doi.org/10.1186/1476-069x-8-40&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1186/1476-069x-8-40&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dippoliti2010&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;D‚ÄôIppoliti, Daniela, Paola Michelozzi, Claudia Marino, Francesca de‚ÄôDonato, Bettina Menne, Klea Katsouyanni, Ursula Kirchmayer, et al. 2010. ‚ÄúThe Impact of Heat Waves on Mortality in 9 European Cities: Results from the EuroHEAT Project.‚Äù &lt;em&gt;Environmental Health&lt;/em&gt; 9 (1). &lt;a href=&#34;https://doi.org/10.1186/1476-069x-9-37&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1186/1476-069x-9-37&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dadvand2012&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Dadvand, Payam, Audrey de Nazelle, Margarita Triguero-Mas, Anna Schembari, Marta Cirach, Elmira Amoly, Francesc Figueras, Xavier Basaga√±a, Bart Ostro, and Mark Nieuwenhuijsen. 2012. ‚ÄúSurrounding Greenness and Exposure to Air Pollution During Pregnancy: An Analysis of Personal Monitoring Data.‚Äù &lt;em&gt;Environmental Health Perspectives&lt;/em&gt; 120 (9): 1286‚Äì90. &lt;a href=&#34;https://doi.org/10.1289/ehp.1104609&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1289/ehp.1104609&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dadvand2019&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Dadvand, Payam, and Mark Nieuwenhuijsen. 2019. ‚ÄúGreen Space and Health.‚Äù In, 409‚Äì23. Springer International Publishing. &lt;a href=&#34;https://doi.org/10.1007/978-3-319-74983-9_20&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/978-3-319-74983-9_20&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dadvand2015&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Dadvand, Payam, Mark J. Nieuwenhuijsen, Mikel Esnaola, Joan Forns, Xavier Basaga√±a, Mar Alvarez-Pedrerol, Ioar Rivas, et al. 2015. ‚ÄúGreen Spaces and Cognitive Development in Primary Schoolchildren.‚Äù &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt; 112 (26): 7937‚Äì42. &lt;a href=&#34;https://doi.org/10.1073/pnas.1503402112&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1073/pnas.1503402112&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-givoni1991&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Givoni, B. 1991. ‚ÄúImpact of Planted Areas on Urban Environmental Quality: A Review.‚Äù &lt;em&gt;Atmospheric Environment. Part B. Urban Atmosphere&lt;/em&gt; 25 (3): 289‚Äì99. &lt;a href=&#34;https://doi.org/10.1016/0957-1272%2891%2990001-u&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/0957-1272(91)90001-u&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-heaviside2017&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Heaviside, Clare, Helen Macintyre, and Sotiris Vardoulakis. 2017. ‚ÄúThe Urban Heat Island: Implications for Health in a Changing Environment.‚Äù &lt;em&gt;Current Environmental Health Reports&lt;/em&gt; 4 (3): 296‚Äì305. &lt;a href=&#34;https://doi.org/10.1007/s40572-017-0150-3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/s40572-017-0150-3&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hoechstetter2011&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Hoechstetter, Sebastian, Ulrich Walz, and Nguyen Xuan Thinh. 2011. ‚ÄúAdapting Lacunarity Techniques for Gradient-Based Analyses of Landscape Surfaces.‚Äù &lt;em&gt;Ecological Complexity&lt;/em&gt; 8 (3): 229‚Äì38. &lt;a href=&#34;https://doi.org/10.1016/j.ecocom.2011.01.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.ecocom.2011.01.001&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-labib2020_review&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Labib, S. M., Sarah Lindley, and Jonny J. Huck. 2020a. ‚ÄúSpatial Dimensions of the Influence of Urban Green-Blue Spaces on Human Health: A Systematic Review.‚Äù &lt;em&gt;Environmental Research&lt;/em&gt; 180 (January): 108869. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2019.108869&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envres.2019.108869&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-labib2020a_lacunarity&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;‚Äî‚Äî‚Äî. 2020b. ‚ÄúScale Effects in Remotely Sensed Greenspace Metrics and How to Mitigate Them for Environmental Health Exposure Assessment.‚Äù &lt;em&gt;Computers, Environment and Urban Systems&lt;/em&gt; 82 (July): 101501. &lt;a href=&#34;https://doi.org/10.1016/j.compenvurbsys.2020.101501&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.compenvurbsys.2020.101501&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-markevych2017&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Markevych, Iana, Julia Schoierer, Terry Hartig, Alexandra Chudnovsky, Perry Hystad, Angel M. Dzhambov, Sjerp de Vries, et al. 2017. ‚ÄúExploring Pathways Linking Greenspace to Health: Theoretical and Methodological Guidance.‚Äù &lt;em&gt;Environmental Research&lt;/em&gt; 158 (October): 301‚Äì17. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2017.06.028&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envres.2017.06.028&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-nori-sarma2022&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Nori-Sarma, Amruta, Shengzhi Sun, Yuantong Sun, Keith R. Spangler, Rachel Oblath, Sandro Galea, Jaimie L. Gradus, and Gregory A. Wellenius. 2022. ‚ÄúAssociation Between Ambient Heat and Risk of Emergency Department Visits for Mental Health Among US Adults, 2010 to 2019.‚Äù &lt;em&gt;JAMA Psychiatry&lt;/em&gt; 79 (4): 341. &lt;a href=&#34;https://doi.org/10.1001/jamapsychiatry.2021.4369&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1001/jamapsychiatry.2021.4369&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-nowak2014&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Nowak, David J., Satoshi Hirabayashi, Allison Bodine, and Eric Greenfield. 2014. ‚ÄúTree and Forest Effects on Air Quality and Human Health in the United States.‚Äù &lt;em&gt;Environmental Pollution&lt;/em&gt; 193 (October): 119‚Äì29. &lt;a href=&#34;https://doi.org/10.1016/j.envpol.2014.05.028&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envpol.2014.05.028&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-paoletti2011&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Paoletti, Elena, Tommaso Bardelli, Gianluca Giovannini, and Leonella Pecchioli. 2011. ‚ÄúAir Quality Impact of an Urban Park over Time.‚Äù &lt;em&gt;Procedia Environmental Sciences&lt;/em&gt; 4: 10‚Äì16. &lt;a href=&#34;https://doi.org/10.1016/j.proenv.2011.03.002&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.proenv.2011.03.002&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-phelan2015&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Phelan, Patrick E., Kamil Kaloush, Mark Miner, Jay Golden, Bernadette Phelan, Humberto Silva, and Robert A. Taylor. 2015. ‚ÄúUrban Heat Island: Mechanisms, Implications, and Possible Remedies.‚Äù &lt;em&gt;Annual Review of Environment and Resources&lt;/em&gt; 40 (1): 285‚Äì307. &lt;a href=&#34;https://doi.org/10.1146/annurev-environ-102014-021155&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1146/annurev-environ-102014-021155&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-su2011&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Su, Jason G., Michael Jerrett, Audrey de Nazelle, and Jennifer Wolch. 2011. ‚ÄúDoes Exposure to Air Pollution in Urban Parks Have Socioeconomic, Racial or Ethnic Gradients?‚Äù &lt;em&gt;Environmental Research&lt;/em&gt; 111 (3): 319‚Äì28. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2011.01.002&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envres.2011.01.002&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-voogt2003&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Voogt, J. A, and T. R Oke. 2003. ‚ÄúThermal Remote Sensing of Urban Climates.‚Äù &lt;em&gt;Remote Sensing of Environment&lt;/em&gt; 86 (3): 370‚Äì84. &lt;a href=&#34;https://doi.org/10.1016/s0034-4257%2803%2900079-8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/s0034-4257(03)00079-8&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>N√ºrnberg - 1. Viewshed Greenness Visibility Index (VGVI)</title>
      <link>https://geobrinkmann.com/post/nuernberg-viewshed-greenness-visibility-index/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://geobrinkmann.com/post/nuernberg-viewshed-greenness-visibility-index/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;visibility of greenspace&lt;/strong&gt; is crucial for understanding how urban environments influence mental health and well-being. In contrast to simple 2D buffer analyses, visibility focuses on the &lt;strong&gt;eye-level perspective&lt;/strong&gt;: how much greenery a person sees from their usual vantage point. One way to estimate this is by using street-view (SV) images (e.g., from Google Street View or Baidu Street View). However, SV-based methods are often limited by seasonal inconsistencies and coverage gaps on roads inaccessible by car (Li et al. 2015). A promising alternative is &lt;strong&gt;viewshed analysis&lt;/strong&gt; within a GIS framework, which can accurately simulate what a person can see from specific locations. Recent studies at city-wide scales show this approach yields highly accurate visibility estimates, without depending on SV image availability (Tabrizian et al. 2020; Labib, Huck, and Lindley 2021; Cimburova and Blumentrath 2022). Improved computation times now allow large-scale assessments of visible greenspace with relatively little effort (Brinkmann, Kremer, and Walker 2022). This measure of greenspace visibility is especially relevant for the restoration pathway, where greenery supports mental recovery (Markevych et al. 2017).&lt;/p&gt;
&lt;p&gt;Ample evidence suggests that &lt;strong&gt;exposure to green spaces can significantly lower stress and restore cognitive function&lt;/strong&gt;. According to the stress reduction theory, natural environments promote stress relief by providing visual cues perceived as safe havens in evolutionary terms (Ulrich 1981; Ulrich et al. 1991). Meanwhile, the &lt;strong&gt;attention restoration&lt;/strong&gt; theory posits that nature helps the mind recover from ‚Äúattention fatigue‚Äù by engaging involuntary attention, thus giving directed attention a chance to rest (Kaplan and Kaplan 1989). Both theories underscore the importance of simply seeing natural elements for psychological benefits. As a result, the inclusion of visibility metrics - from either street-view imagery or GIS-based viewshed analysis - can add vital insights into how greenspace fosters restoration and supports better mental health outcomes (Dadvand et al. 2016).&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;The relevant spatial datasets have been uploaded on Zenodo: administrative boundaries (AOI), DTM and DSM rasters, and a binary land-cover raster for greenspace analysis. All raster data is available at 1m resolution.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dplyr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;terra&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;CGEI&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;https://zenodo.org/records/14633167/files/&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# AOI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;read_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;01_Nbg_Bezirke.gpkg&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code_bez&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;97&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# This is not available in the GAVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;group_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;code_bez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name_bez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;summarise&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;ungroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# DSM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dsm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_dsm_1m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# DTM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dtm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_dtm_1m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Greenspace (binary)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;lulc&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;rast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zenodo_url&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;03_ndvi_01_1m.tif&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;img src=&#34;https://geobrinkmann.com/post/nuernberg-viewshed-greenness-visibility-index/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;960&#34; /&gt;
&lt;p&gt;N√ºrnberg, shown on the left in grey, is divided into 86 administrative districts. M√∂geldorf has been highlighted in orange to provide examples of the three key greenness metrics on the right:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DTM&lt;/strong&gt; - The Digital Terrain Model illustrates the bare earth‚Äôs surface elevation, excluding buildings and vegetation. In the map, higher terrain is depicted in brownish colors, transitioning to green in lower-lying areas.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DSM&lt;/strong&gt; - The Digital Surface Model includes all features above ground (e.g., buildings, trees). The green and yellow shades indicate varying heights, reflecting how built-up areas and vegetation rise above the terrain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LULC&lt;/strong&gt; - The land-use/land-cover map distinguishes vegetated (green) from non-vegetated (red) areas, making it easy to spot where greenery dominates versus dense urban structures.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;vgvi&#34;&gt;VGVI&lt;/h2&gt;
&lt;p&gt;A key measure of &lt;strong&gt;eye-level&lt;/strong&gt; greenspace exposure is the Viewshed Greenness Visibility Index (&lt;strong&gt;VGVI&lt;/strong&gt;) (Labib, Huck, and Lindley 2021). This metric quantifies how much greenery (based on a binary LULC layer) is visible from a given point when accounting for local surface elevations (DSM) and terrain elevations (DTM).&lt;/p&gt;
&lt;h3 id=&#34;1-defining-observer-locations&#34;&gt;1. Defining Observer Locations&lt;/h3&gt;
&lt;p&gt;To simulate where an individual might stand, we first identify valid observer points at a 5 m resolution, excluding areas where buildings or other tall structures exceed the observer‚Äôs eye height (e.g., 2.2 m above ground). The code below shows how we aggregate DSM and DTM to 5 m, filter for valid points &lt;code&gt;(dsm5 &amp;lt;= dtm5 + 2.2)&lt;/code&gt;, and convert these locations into an SF object:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# First we need all valid cells in a 5x5m grid. These are where the DSM is not&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# higher than 1.8m + DTM&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dsm5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aggregate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dsm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dtm5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aggregate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dsm5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtm5&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;obs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;crop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs_vals&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs_vals&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;which&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obs_vals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Convert the cell coordinates as an SF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs_sf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;terra&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;xyFromCell&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;obs_vals&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;obs_sf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;st_as_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as_tibble&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;obs_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;y&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;crs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;crs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dsm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mutate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;relocate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-calculating-the-vgvi&#34;&gt;2. Calculating the VGVI&lt;/h3&gt;
&lt;p&gt;With all potential observer locations defined, we compute the &lt;strong&gt;VGVI&lt;/strong&gt; using a &lt;strong&gt;viewshed&lt;/strong&gt; approach. In brief:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The observer‚Äôs eye height (2.2 m) is placed atop the DTM, and any obstacles (e.g., buildings, trees) in the DSM are considered.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Each visible line-of-sight cell in a viewshed is checked against the binary greenspace raster (LULC).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A distance decay function reduces the weight of objects further away (e.g., &lt;strong&gt;exponential&lt;/strong&gt; with m=1m and b=3).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is the &lt;code&gt;vgvi()&lt;/code&gt; function call from the &lt;a href=&#34;https://github.com/STBrinkmann/CGEI/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;CGEI&lt;/strong&gt;&lt;/a&gt; R package that performs these steps in parallel:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Calculate VGVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_sf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;vgvi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;obs_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;dsm_rast&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dsm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtm_rast&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dtm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;greenspace_rast&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lulc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;max_distance&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;observer_height&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2.2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;exponential&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;cores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;progress&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3-interpolating-vgvi-to-a-continuous-surface&#34;&gt;3. Interpolating VGVI to a Continuous Surface&lt;/h3&gt;
&lt;p&gt;Finally, the point-based VGVI results (one value per observer location) are interpolated to a continuous 10 m resolution raster using &lt;strong&gt;Inverse Distance Weighting (IDW)&lt;/strong&gt;. IDW assumes nearby values are more similar than distant ones, so each unknown cell‚Äôs VGVI is a distance-weighted average of its nearest neighbors (Hartmann, Krois, and Waske 2018). Relevant parameters (e.g., number of neighbors, distance threshold) can be fine-tuned based on sensitivity analysis.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Now rasterize the VGVI&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_sf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vgvi_sf[aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_05&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sf_interpolat_IDW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;observer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vgvi_sf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;VGVI&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;raster_res&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;beta&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;max_distance&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;na_only&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                                  &lt;span class=&#34;n&#34;&gt;cores&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;22&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;progress&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Bring to 10m resolution&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;aggregate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_05&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;crop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&amp;gt;%&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;mask&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;aoi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, the &lt;strong&gt;VGVI&lt;/strong&gt; raster can be classified using &lt;strong&gt;Jenks natural breaks&lt;/strong&gt; to highlight different visibility classes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Classify the VGVI using Jenks natural breaks - N=9&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CGEI&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:::&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;reclassify_jenks&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;9&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;as.int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vgvi_rast_10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;VGVI&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Below is the &lt;strong&gt;final VGVI map&lt;/strong&gt; for N√ºrnberg, showing how much greenspace is visible from an eye-level perspective at each location. Areas in &lt;strong&gt;red&lt;/strong&gt; represent lower greenness visibility, whereas &lt;strong&gt;green&lt;/strong&gt; areas indicate higher greenness visibility. As expected, more &lt;strong&gt;densely built-up&lt;/strong&gt; districts near the city center display lower VGVI values, while &lt;strong&gt;peripheral areas&lt;/strong&gt; - which often have less building coverage and more open space - reveal higher VGVI values.&lt;/p&gt;
&lt;p&gt;Overall, this view-dependent approach highlights not only &lt;em&gt;where&lt;/em&gt; greenspace is located, but also &lt;em&gt;how much&lt;/em&gt; of it is actually visible to an individual walking through the city - critical information for urban design, mental health research, and ecological planning.&lt;/p&gt;
&lt;img src=&#34;https://geobrinkmann.com/post/nuernberg-viewshed-greenness-visibility-index/index.en_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; entry-spacing=&#34;0&#34;&gt;
&lt;div id=&#34;ref-brinkmann2022_agile&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Brinkmann, Sebastian T., Dominik Kremer, and Blake Byron Walker. 2022. ‚ÄúModelling Eye-Level Visibility of Urban Green Space: Optimising City-Wide Point-Based Viewshed Computations Through Prototyping.‚Äù &lt;em&gt;AGILE: GIScience Series&lt;/em&gt; 3 (June): 1‚Äì7. &lt;a href=&#34;https://doi.org/10.5194/agile-giss-3-27-2022&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.5194/agile-giss-3-27-2022&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cimburova2022&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Cimburova, Zofie, and Stefan Blumentrath. 2022. ‚ÄúViewshed-Based Modelling of Visual Exposure to Urban Greenery An Efficient GIS Tool for Practical Planning Applications.‚Äù &lt;em&gt;Landscape and Urban Planning&lt;/em&gt; 222 (June): 104395. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2022.104395&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.landurbplan.2022.104395&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-dadvand2016&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Dadvand, Payam, Xavier Bartoll, Xavier Basaga√±a, Albert Dalmau-Bueno, David Martinez, Albert Ambros, Marta Cirach, et al. 2016. ‚ÄúGreen Spaces and General Health: Roles of Mental Health Status, Social Support, and Physical Activity.‚Äù &lt;em&gt;Environment International&lt;/em&gt; 91 (May): 161‚Äì67. &lt;a href=&#34;https://doi.org/10.1016/j.envint.2016.02.029&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envint.2016.02.029&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hartmann2018&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Hartmann, K., J. Krois, and B. Waske. 2018. ‚ÄúE-Learning Project SOGA: Statistics and Geospatial Data Analysis.‚Äù &lt;em&gt;Department of Geographiy, University of Kansas Occasional Paper&lt;/em&gt;. &lt;a href=&#34;https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/geostatistics/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/geostatistics/index.html&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kaplan1989&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Kaplan, R., and S. Kaplan. 1989. ‚ÄúThe Experience of Nature: A Psychological Perspective.‚Äù &lt;em&gt;New York: Cambridge University Press&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-labib2021a_visibility&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Labib, S. M., Jonny J. Huck, and Sarah Lindley. 2021. ‚ÄúModelling and Mapping Eye-Level Greenness Visibility Exposure Using Multi-Source Data at High Spatial Resolutions.‚Äù &lt;em&gt;Science of The Total Environment&lt;/em&gt; 755 (February): 143050. &lt;a href=&#34;https://doi.org/10.1016/j.scitotenv.2020.143050&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.scitotenv.2020.143050&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-li2015&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Li, Xiaojiang, Chuanrong Zhang, Weidong Li, Robert Ricard, Qingyan Meng, and Weixing Zhang. 2015. ‚ÄúAssessing Street-Level Urban Greenery Using Google Street View and a Modified Green View Index.‚Äù &lt;em&gt;Urban Forestry &amp;amp; Urban Greening&lt;/em&gt; 14 (3): 675‚Äì85. &lt;a href=&#34;https://doi.org/10.1016/j.ufug.2015.06.006&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.ufug.2015.06.006&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-markevych2017&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Markevych, Iana, Julia Schoierer, Terry Hartig, Alexandra Chudnovsky, Perry Hystad, Angel M. Dzhambov, Sjerp de Vries, et al. 2017. ‚ÄúExploring Pathways Linking Greenspace to Health: Theoretical and Methodological Guidance.‚Äù &lt;em&gt;Environmental Research&lt;/em&gt; 158 (October): 301‚Äì17. &lt;a href=&#34;https://doi.org/10.1016/j.envres.2017.06.028&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.envres.2017.06.028&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-tabrizian2020&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Tabrizian, Payam, Perver K. Baran, Derek Van Berkel, Helena Mitasova, and Ross Meentemeyer. 2020. ‚ÄúModeling Restorative Potential of Urban Environments by Coupling Viewscape Analysis of Lidar Data with Experiments in Immersive Virtual Environments.‚Äù &lt;em&gt;Landscape and Urban Planning&lt;/em&gt; 195 (March): 103704. &lt;a href=&#34;https://doi.org/10.1016/j.landurbplan.2019.103704&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.landurbplan.2019.103704&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ulrich1981&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Ulrich, Roger S. 1981. ‚ÄúNatural Versus Urban Scenes.‚Äù &lt;em&gt;Environment and Behavior&lt;/em&gt; 13 (5): 523‚Äì56. &lt;a href=&#34;https://doi.org/10.1177/0013916581135001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1177/0013916581135001&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ulrich1991&#34; class=&#34;csl-entry&#34;&gt;
&lt;p&gt;Ulrich, Roger S., Robert F. Simons, Barbara D. Losito, Evelyn Fiorito, Mark A. Miles, and Michael Zelson. 1991. ‚ÄúStress Recovery During Exposure to Natural and Urban Environments.‚Äù &lt;em&gt;Journal of Environmental Psychology&lt;/em&gt; 11 (3): 201‚Äì30. &lt;a href=&#34;https://doi.org/10.1016/s0272-4944%2805%2980184-7&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/s0272-4944(05)80184-7&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
